<?xml version="1.0" ?><!DOCTYPE PubmedArticleSet PUBLIC "-//NLM//DTD PubMedArticle, 1st June 2018//EN" "https://dtd.nlm.nih.gov/ncbi/pubmed/out/pubmed_180601.dtd"><PubmedArticleSet><PubmedArticle>    <MedlineCitation Status="Publisher" Owner="NLM">        <PMID Version="1">30318761</PMID>        <DateRevised>            <Year>2018</Year>            <Month>11</Month>            <Day>13</Day>        </DateRevised>        <Article PubModel="Print-Electronic">            <Journal>                <ISSN IssnType="Electronic">1864-0648</ISSN>                <JournalIssue CitedMedium="Internet">                    <PubDate>                        <Year>2018</Year>                        <Month>Oct</Month>                        <Day>14</Day>                    </PubDate>                </JournalIssue>                <Title>Journal of biophotonics</Title>                <ISOAbbreviation>J Biophotonics</ISOAbbreviation>            </Journal>            <ArticleTitle>Automated assessment of breast cancer margin in optical coherence tomography images via pretrained convolutional neural network.</ArticleTitle>            <Pagination>                <MedlinePgn>e201800255</MedlinePgn>            </Pagination>            <ELocationID EIdType="doi" ValidYN="Y">10.1002/jbio.201800255</ELocationID>            <Abstract>                <AbstractText>The benchmark method for the evaluation of breast cancers involves microscopic testing of a hematoxylin and eosin (H&amp;E)-stained tissue biopsy. Resurgery is required in 20% to 30% of cases because of incomplete excision of malignant tissues. Therefore, a more accurate method is required to detect the cancer margin to avoid the risk of recurrence. In the recent years, convolutional neural networks (CNNs) has achieved excellent performance in the field of medical images diagnosis. It automatically extracts the features from the images and classifies them. In the proposed study, we apply a pretrained Inception-v3 CNN with reverse active learning for the classification of healthy and malignancy breast tissue using optical coherence tomography (OCT) images. This proposed method attained the sensitivity, specificity and accuracy is 90.2%, 91.7% and 90%, respectively, with testing datasets collected from 48 patients (22 normal fibro-adipose tissue and 26 Invasive ductal carcinomas cancerous tissues). The trained network utilizes for the breast cancer margin assessment to predict the tumor with negative margins. Additionally, the network output is correlated with the corresponding histology image. Our results lay the foundation for the future that the proposed method can be used to perform automatic intraoperative identification of breast cancer margins in real-time and to guide core needle biopsies.</AbstractText>                <CopyrightInformation>Â© 2018 WILEY-VCH Verlag GmbH &amp; Co. KGaA, Weinheim.</CopyrightInformation>            </Abstract>            <AuthorList CompleteYN="Y">                <Author ValidYN="Y">                    <LastName>Singla</LastName>                    <ForeName>Neeru</ForeName>                    <Initials>N</Initials>                    <Identifier Source="ORCID">https://orcid.org/0000-0001-8710-6278</Identifier>                    <AffiliationInfo>                        <Affiliation>Department of Electrical and Instrumentation Engineering, Thapar Institute of Engineering and Technology, Patiala, Punjab, India.</Affiliation>                    </AffiliationInfo>                </Author>                <Author ValidYN="Y">                    <LastName>Dubey</LastName>                    <ForeName>Kavita</ForeName>                    <Initials>K</Initials>                    <AffiliationInfo>                        <Affiliation>Department of Electrical and Instrumentation Engineering, Thapar Institute of Engineering and Technology, Patiala, Punjab, India.</Affiliation>                    </AffiliationInfo>                </Author>                <Author ValidYN="Y">                    <LastName>Srivastava</LastName>                    <ForeName>Vishal</ForeName>                    <Initials>V</Initials>                    <Identifier Source="ORCID">https://orcid.org/0000-0001-9097-4869</Identifier>                    <AffiliationInfo>                        <Affiliation>Department of Electrical and Instrumentation Engineering, Thapar Institute of Engineering and Technology, Patiala, Punjab, India.</Affiliation>                    </AffiliationInfo>                    <AffiliationInfo>                        <Affiliation>Department of Electrical and Computer Engineering, University of California Los Angeles, Los Angeles, California.</Affiliation>                    </AffiliationInfo>                </Author>            </AuthorList>            <Language>eng</Language>            <GrantList CompleteYN="Y">                <Grant>                    <GrantID>EMR/2016/000677</GrantID>                    <Agency>Department of Science and Technology</Agency>                    <Country/>                </Grant>            </GrantList>            <PublicationTypeList>                <PublicationType UI="D016428">Journal Article</PublicationType>            </PublicationTypeList>            <ArticleDate DateType="Electronic">                <Year>2018</Year>                <Month>10</Month>                <Day>14</Day>            </ArticleDate>        </Article>        <MedlineJournalInfo>            <Country>Germany</Country>            <MedlineTA>J Biophotonics</MedlineTA>            <NlmUniqueID>101318567</NlmUniqueID>            <ISSNLinking>1864-063X</ISSNLinking>        </MedlineJournalInfo>        <KeywordList Owner="NOTNLM">            <Keyword MajorTopicYN="N">breast cancer tissue</Keyword>            <Keyword MajorTopicYN="N">deep convolutional neural network</Keyword>            <Keyword MajorTopicYN="N">optical coherence tomography</Keyword>            <Keyword MajorTopicYN="N">transfer learning</Keyword>        </KeywordList>    </MedlineCitation>    <PubmedData>        <History>            <PubMedPubDate PubStatus="received">                <Year>2018</Year>                <Month>07</Month>                <Day>07</Day>            </PubMedPubDate>            <PubMedPubDate PubStatus="accepted">                <Year>2018</Year>                <Month>10</Month>                <Day>12</Day>            </PubMedPubDate>            <PubMedPubDate PubStatus="pubmed">                <Year>2018</Year>                <Month>10</Month>                <Day>16</Day>                <Hour>6</Hour>                <Minute>0</Minute>            </PubMedPubDate>            <PubMedPubDate PubStatus="medline">                <Year>2018</Year>                <Month>10</Month>                <Day>16</Day>                <Hour>6</Hour>                <Minute>0</Minute>            </PubMedPubDate>            <PubMedPubDate PubStatus="entrez">                <Year>2018</Year>                <Month>10</Month>                <Day>16</Day>                <Hour>6</Hour>                <Minute>0</Minute>            </PubMedPubDate>        </History>        <PublicationStatus>aheadofprint</PublicationStatus>        <ArticleIdList>            <ArticleId IdType="pubmed">30318761</ArticleId>            <ArticleId IdType="doi">10.1002/jbio.201800255</ArticleId>        </ArticleIdList>    </PubmedData></PubmedArticle></PubmedArticleSet>